# This is a basic workflow that is manually triggered
name: YT comments scraping workflow

on:
  workflow_dispatch:
    inputs:
      youtuber:
        description: "The youtuber's name, use letters only which will be used as table names"
        default: 'mybeast'
        required: true
        type: string
      channel:
        description: 'The url of the channel, example: https://www.youtube.com/playlist?list=PLoSWVnSA9vG9qV0CVCpg5WwEy3LiP7udY'
        default: 'https://www.youtube.com/playlist?list=PLoSWVnSA9vG9qV0CVCpg5WwEy3LiP7udY'
        required: true
        type: string

jobs:
  scrape_urls:
    outputs:
      matrix: ${{ steps.matrix.outputs.matrix }}

    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'
    steps:
    #- id: set-matrix
    #  run: echo "::set-output name=matrix::{\"include\":[{\"project\":\"foo\",\"config\":\"Debug\"},{\"project\":\"bar\",\"config\":\"Release\"}]}"
  
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: '3.10' 
    - name: Install Python dependencies
      run: python -m pip install --upgrade pip pandas pandas_gbq pytube requests joblib fsspec gcsfs
    - uses: 'google-github-actions/auth@v2'
      with:
        service_account: 'sunlit-core-205604@sunlit-core-205604.iam.gserviceaccount.com'
        workload_identity_provider: 'projects/570510735077/locations/global/workloadIdentityPools/github/providers/yt-comment-analysis'

    - uses: google-github-actions/setup-gcloud@v2
    - name: Run gcloud
      run: |
        gcloud compute instances list
        gsutil -i sunlit-core-205604@sunlit-core-205604.iam.gserviceaccount.com ls gs://hmei-bucket

    - name: execute py script
      id: matrix
      run: |
        python ytcomments/comment.py --youtuber=${{ inputs.youtuber }} --channel=${{ inputs.channel }}
        export FILE_LIST="[$(gsutil ls gs://hmei-bucket/data/mybeast/ | sed 's/\(.*\)/"\1"/g' | sed -z 's/\n/, /g'| sed 's/..$//')]"
        echo matrix=$FILE_LIST >> "$GITHUB_OUTPUT"
        cat "$GITHUB_OUTPUT"

  scrape:
    runs-on: ubuntu-latest
    needs: scrape_urls
    strategy:
      matrix:
        fid: ${{ fromJSON(needs.scrape_urls.outputs.matrix) }}
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
    - run: echo scraping urls in ${{ matrix.fid }} ...
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: '3.10' 
    - name: Install Python dependencies
      run: python -m pip install --upgrade pip pandas pandas_gbq pytube requests joblib fsspec gcsfs
    - uses: 'google-github-actions/auth@v2'
      with:
        service_account: 'sunlit-core-205604@sunlit-core-205604.iam.gserviceaccount.com'
        workload_identity_provider: 'projects/570510735077/locations/global/workloadIdentityPools/github/providers/yt-comment-analysis'
    - name: execute py script
      run: |
        python ytcomments/comment.py --youtuber=${{ inputs.youtuber }} --fid=${{ matrix.fid }}


# conclude
  conclude:
    needs: scrape
    runs-on: ubuntu-latest
    steps:
    - name: Conclude here
      run: lscpu; lsmem; echo "Finished scraping ${{ inputs.youtuber }}:${{ inputs.channel }}"